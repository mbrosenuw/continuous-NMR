{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous NMR analysis\n",
    "\n",
    "Use this template as a starting point to carry out the analysis tasks.  For reference, here are links to recommended Python resources: the [Whirlwind Tour of Python](https://jakevdp.github.io/WhirlwindTourOfPython/) and the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) both by Jake VanderPlas.\n",
    "\n",
    "## Standard Packages\n",
    "\n",
    "This is a good idea at the beginning of your notebook to include the packages that you will need.  We will use those shown below here.  A brief description:\n",
    "* `numpy` is the foundational package for Python numerical work. It extends and speeds up array operations beyond standard Python, and it includes almost all math functions that you would need for example `sqrt()` (square root) or `cos()` (cosine).  These would be written in code as `np.sqrt()` or `np.cos()`.\n",
    "* `scipy` is a huge collection of scientific data analysis functions, routines, physicical constants, etc.  This is the second most used package for scientific work. Here we will use the physical constants library, `scipy.constants`.  Documentation is at [SciPy.org](https://docs.scipy.org/doc/scipy/reference/) with the constants subpackage at https://docs.scipy.org/doc/scipy/reference/constants.html.\n",
    "* `uncertainties` is a very useful small package that simplifies uncertainty propagation and printing out of quantities with uncertainty. Documentation is at https://pythonhosted.org/uncertainties/\n",
    "* `matplotlib` is *the* standard plotting package for scientific Python.  We will use a subset called `pyplot` which is modeled after the plotting functions used in MATLAB. The last line below, `%matplotlib inline`, simply forces the plots to appear within the notebook.\n",
    "* `pandas` is a large data science package.  It's main feature is a set of methods to create and manipulate a \"DataFrame,\" which is an enlargement of the idea of an array.  I plays well with NumPy and other packages.  We will use it mainly as a way to read files into data sets in an easy way.\n",
    "* [LMFit](https://lmfit.github.io/lmfit-py/) is excellent for carrying out line and curve fits with many useful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Help\n",
    "\n",
    "See the example code for a wide range of actions in notebooks created by Prof. Marjorie Olmstead and Prof. David Pengra in this repository: [**Physics431/Examples**](https://github.com/Physics431/Examples).\n",
    "\n",
    "You can pull the examples into your environment with the following command.  (Only do this once, or you will get an error):\n",
    "\n",
    "    git clone https://github.com/Physics431/Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Summary\n",
    "\n",
    "#### Measure $\\gamma$ for protons\n",
    "1. Import measurements of frequency and magnetic field taken multiple times (5-10) in order to establish uncertainty of individual measurements.  \n",
    "2. Calculate the mean and standard deviation of each set of measurements.  Also calculate the percent uncetainty in each set. Use these results to establish uncertainties on the rest of the data points.\n",
    "3. Import measurements of the resonant frequency $f_{\\rm res}$ vs. static field $B_0$ for protons in water (+CuSO<sub>4</sub>) across the range of frequencies available with the oscillator.  \n",
    "4. Include the uncertainty calculated in step 2.\n",
    "5. Make a line fit and a plot of the data with the fit (use LMfit) to get the slope of $f_{\\rm res}$ versus $B_0$.\n",
    "6. Calculate $\\gamma$ and the $g$-factor for the proton, including uncertainty.\n",
    "\n",
    "#### Measure the resonance of <sup>19</sup>F versus <sup>1</sup>H\n",
    "1. Import measurements listing measured B-field along with resonant frequencies of <sup>1</sup>H and <sup>19</sup>F at those field strengths.\n",
    "2. Fit a line to the resonant frequency of <sup>19</sup>F versus resonant frequency of <sup>1</sup>H from the above data set, plot it (use LMfit) and obtain slope and its uncertainty.\n",
    "3. From the results calculate $\\gamma$ and associated $g$-factor for <sup>19</sup>F from the fit result and the accepted values known for <sup>1</sup>H.\n",
    "4. Comment in your Group Notebook on the topic of observable chemical shift for fluorine\n",
    "\n",
    "#### Trend of $T_2^*$ with paramagnetic ion concentration\n",
    "If you can get quantitative values for how $T_2^*$ decays for a range of concentration, make a plot to see the trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:38:17.752526Z",
     "start_time": "2025-01-09T23:38:17.681223Z"
    }
   },
   "outputs": [],
   "source": [
    "# Usually import packages via a handle to the functions in them using import ... as ...\n",
    "#\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import uncertainties as unc\n",
    "import scipy.constants as const\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:38:17.754664Z",
     "start_time": "2025-01-09T23:38:17.752059Z"
    }
   },
   "outputs": [],
   "source": [
    "# Useful plot default\n",
    "mpl.rcParams['figure.figsize'] = 12.0,8.0  # Roughly 12 cm wde by 8 cm high\n",
    "mpl.rcParams['font.size'] = 14.0 # Use 14 point font"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnetic moment of the proton\n",
    "\n",
    "### Read in the multi-measurement data\n",
    "\n",
    "You should have a spreadsheet (CSV) with columns or rows of like measurements of frequency and field for a set of steady fields (at least 3 sets of 10 across the range of useable oscillator frequencies).  Import these data with Pandas `pd.read_csv()`:\n",
    "    \n",
    "    multi_data = pd.read_csv('multi-measurement_NMR_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:54:37.396622Z",
     "start_time": "2025-01-09T23:54:37.387264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      B1      f1    B2      f2    B3      f3    B4      f4    B5      f5   B6  \\\n0  1.899  8.1668  2.04  8.7700  2.18  9.3734  2.32  9.9723  2.46  10.573  2.6   \n1  1.899  8.1665  2.04  8.7699  2.18  9.3731  2.32  9.9724  2.46  10.573  2.6   \n2  1.899  8.1667  2.04  8.7705  2.18  9.3734  2.32  9.9724  2.46  10.574  2.6   \n3  1.899  8.1669  2.04  8.7705  2.18  9.3734  2.32  9.9727  2.46  10.574  2.6   \n4  1.899  8.1666  2.04  8.7701  2.18  9.3731  2.32  9.9726  2.46  10.574  2.6   \n\n       f6  \n0  11.167  \n1  11.166  \n2  11.167  \n3  11.167  \n4  11.166  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>B1</th>\n      <th>f1</th>\n      <th>B2</th>\n      <th>f2</th>\n      <th>B3</th>\n      <th>f3</th>\n      <th>B4</th>\n      <th>f4</th>\n      <th>B5</th>\n      <th>f5</th>\n      <th>B6</th>\n      <th>f6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.899</td>\n      <td>8.1668</td>\n      <td>2.04</td>\n      <td>8.7700</td>\n      <td>2.18</td>\n      <td>9.3734</td>\n      <td>2.32</td>\n      <td>9.9723</td>\n      <td>2.46</td>\n      <td>10.573</td>\n      <td>2.6</td>\n      <td>11.167</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.899</td>\n      <td>8.1665</td>\n      <td>2.04</td>\n      <td>8.7699</td>\n      <td>2.18</td>\n      <td>9.3731</td>\n      <td>2.32</td>\n      <td>9.9724</td>\n      <td>2.46</td>\n      <td>10.573</td>\n      <td>2.6</td>\n      <td>11.166</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.899</td>\n      <td>8.1667</td>\n      <td>2.04</td>\n      <td>8.7705</td>\n      <td>2.18</td>\n      <td>9.3734</td>\n      <td>2.32</td>\n      <td>9.9724</td>\n      <td>2.46</td>\n      <td>10.574</td>\n      <td>2.6</td>\n      <td>11.167</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.899</td>\n      <td>8.1669</td>\n      <td>2.04</td>\n      <td>8.7705</td>\n      <td>2.18</td>\n      <td>9.3734</td>\n      <td>2.32</td>\n      <td>9.9727</td>\n      <td>2.46</td>\n      <td>10.574</td>\n      <td>2.6</td>\n      <td>11.167</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.899</td>\n      <td>8.1666</td>\n      <td>2.04</td>\n      <td>8.7701</td>\n      <td>2.18</td>\n      <td>9.3731</td>\n      <td>2.32</td>\n      <td>9.9726</td>\n      <td>2.46</td>\n      <td>10.574</td>\n      <td>2.6</td>\n      <td>11.166</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data to a Pandas dataframe and print a table.\n",
    "df = pd.read_csv('exercise1_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the multiple measurements in the dataframe `df` are in a column with name `'col_name'` you an calculat the mean and standard deviation with the internal methods like this:\n",
    "\n",
    "    col_mean = df['col_name'].mean()\n",
    "    col_std_dev = df['col_name'].std()\n",
    "    \n",
    "Then the percent uncertainty is just the ratio of the standard deviation to the mean ($\\times$100).  Calculate this too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:57:41.448744Z",
     "start_time": "2025-01-09T23:57:41.442956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.1667, 8.770199999999999, 9.373280000000001, 9.972480000000001, 10.573599999999999]\n",
      "[0.0001581138830086122, 0.0002828427124749019, 0.0001643167672511669, 0.0001643167672511669, 0.0005477225575048625]\n",
      "[0.0019360804610015331, 0.0032250429006738944, 0.0017530338072816226, 0.0016477021488252358, 0.0051800953081718865]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the requested quantities\n",
    "class measure:\n",
    "    def __init__(self, df, bname, mname):\n",
    "        self.b = df[bname].mean()\n",
    "        self.m = df[mname]\n",
    "        self.fmean = self.m.mean()\n",
    "        self.fstd = self.m.std()\n",
    "        self.uncert = self.fstd/self.fmean * 100\n",
    "\n",
    "m1 = measure(df, 'B1', 'f1')\n",
    "m2 = measure(df, 'B2', 'f2')\n",
    "m3 = measure(df, 'B3', 'f3')\n",
    "m4 = measure(df, 'B4', 'f4')\n",
    "m5 = measure(df, 'B5', 'f5')\n",
    "measurements = [m1, m2, m3, m4, m5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the standard deviations are (nearly) the same, you can use one number for the uncertainty in a frequency or field measurement.  If they are different, check the percent uncertainty.  If these are (nearly) the same, then the data-point uncertainty can be given by the value times this percent uncertainty. If these are different, then you should use an interpolation function to calculate the uncertainty in a data point.\n",
    "\n",
    "The Python libraries provide just such a function: the **SciPy** `interpolate` package, which you can read about here: [SciPy Interpolate](https://docs.scipy.org/doc/scipy/reference/reference/interpolate.html).\n",
    "\n",
    "The SciPy function to use is `interp1d()`.  Notice that it creates a *function*. To create the interpolation function, you feed it your feed it your list of uncertainties versus frequency or uncertainties versus field, then use the result with your array of values of $f_{\\rm res}$ versus $B_0$ to obtain the uncertainty for each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T00:01:16.088289Z",
     "start_time": "2025-01-10T00:01:16.081435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.1667, 8.770199999999999, 9.373280000000001, 9.972480000000001, 10.573599999999999]\n",
      "[0.0001581138830086122, 0.0002828427124749019, 0.0001643167672511669, 0.0001643167672511669, 0.0005477225575048625]\n",
      "[0.0019360804610015331, 0.0032250429006738944, 0.0017530338072816226, 0.0016477021488252358, 0.0051800953081718865]\n"
     ]
    }
   ],
   "source": [
    "# Make a table of the uncertainty calculation to easily compare the values across the measurement range.\n",
    "means = [m.fmean for m in measurements]\n",
    "sigmas = [m.fstd for m in measurements]\n",
    "uncerts = [m.uncert for m in measurements]\n",
    "print(means)\n",
    "print(sigmas)\n",
    "print(uncerts)\n",
    "\n",
    "#these standard deviations are close enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the resonance data for protons\n",
    "\n",
    "Use `read_csv()` as before.  You should have a table with at least 2 columns: resonance frequency and magnetic field. \n",
    "\n",
    "Print a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T00:02:36.580810Z",
     "start_time": "2025-01-10T00:02:36.577151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      B1      f1    B2      f2    B3      f3    B4      f4    B5      f5   B6  \\\n0  1.899  8.1668  2.04  8.7700  2.18  9.3734  2.32  9.9723  2.46  10.573  2.6   \n1  1.899  8.1665  2.04  8.7699  2.18  9.3731  2.32  9.9724  2.46  10.573  2.6   \n2  1.899  8.1667  2.04  8.7705  2.18  9.3734  2.32  9.9724  2.46  10.574  2.6   \n3  1.899  8.1669  2.04  8.7705  2.18  9.3734  2.32  9.9727  2.46  10.574  2.6   \n4  1.899  8.1666  2.04  8.7701  2.18  9.3731  2.32  9.9726  2.46  10.574  2.6   \n\n       f6  \n0  11.167  \n1  11.166  \n2  11.167  \n3  11.167  \n4  11.166  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>B1</th>\n      <th>f1</th>\n      <th>B2</th>\n      <th>f2</th>\n      <th>B3</th>\n      <th>f3</th>\n      <th>B4</th>\n      <th>f4</th>\n      <th>B5</th>\n      <th>f5</th>\n      <th>B6</th>\n      <th>f6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.899</td>\n      <td>8.1668</td>\n      <td>2.04</td>\n      <td>8.7700</td>\n      <td>2.18</td>\n      <td>9.3734</td>\n      <td>2.32</td>\n      <td>9.9723</td>\n      <td>2.46</td>\n      <td>10.573</td>\n      <td>2.6</td>\n      <td>11.167</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.899</td>\n      <td>8.1665</td>\n      <td>2.04</td>\n      <td>8.7699</td>\n      <td>2.18</td>\n      <td>9.3731</td>\n      <td>2.32</td>\n      <td>9.9724</td>\n      <td>2.46</td>\n      <td>10.573</td>\n      <td>2.6</td>\n      <td>11.166</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.899</td>\n      <td>8.1667</td>\n      <td>2.04</td>\n      <td>8.7705</td>\n      <td>2.18</td>\n      <td>9.3734</td>\n      <td>2.32</td>\n      <td>9.9724</td>\n      <td>2.46</td>\n      <td>10.574</td>\n      <td>2.6</td>\n      <td>11.167</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.899</td>\n      <td>8.1669</td>\n      <td>2.04</td>\n      <td>8.7705</td>\n      <td>2.18</td>\n      <td>9.3734</td>\n      <td>2.32</td>\n      <td>9.9727</td>\n      <td>2.46</td>\n      <td>10.574</td>\n      <td>2.6</td>\n      <td>11.167</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.899</td>\n      <td>8.1666</td>\n      <td>2.04</td>\n      <td>8.7701</td>\n      <td>2.18</td>\n      <td>9.3731</td>\n      <td>2.32</td>\n      <td>9.9726</td>\n      <td>2.46</td>\n      <td>10.574</td>\n      <td>2.6</td>\n      <td>11.166</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data, and print the dataframe\n",
    "\n",
    "#why\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T00:02:36.688710Z",
     "start_time": "2025-01-10T00:02:36.685030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on the result of the uncertainty analysis above, construct uncertainty arrays\n",
    "# to go with the data according to those instructions.\n",
    "\n",
    "# Include the uncertainty results as another column in the dataframe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the data to extract the slope\n",
    "\n",
    "Use LMfit.  See the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:38:17.784212Z",
     "start_time": "2025-01-09T23:38:17.764305Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lmfit'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Set  up the Model\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Import the Linear model.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# You only do this once in a notebook\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlmfit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LinearModel\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# create an instance of the model\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# You only need to do this once\u001B[39;00m\n\u001B[1;32m      9\u001B[0m line \u001B[38;5;241m=\u001B[39m LinearModel()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'lmfit'"
     ]
    }
   ],
   "source": [
    "# Set  up the Model\n",
    "\n",
    "# Import the Linear model.\n",
    "# You only do this once in a notebook\n",
    "from lmfit.models import LinearModel\n",
    "\n",
    "# create an instance of the model\n",
    "# You only need to do this once\n",
    "line = LinearModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-09T23:38:17.776853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get starting parameters.  Example:\n",
    "# start_params = line.guess(y_data, x=x_data\n",
    "\n",
    "# Feed these into the fitter and run it. Example:\n",
    "# Line_fit = line.fit(y_data, start_params, x=x_data, weights=1/y_data_unc)\n",
    "\n",
    "# Print the fit results. Example\n",
    "# Line_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2025-01-09T23:38:17.777959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a plot.  Example\n",
    "# Line_fit.plot()\n",
    "# plt.grid(True)\n",
    "# plt.title('NMR resonance measurement for protons')\n",
    "# plt.xlabel('Magnetic field (kG)')\n",
    "# plt.ylabel('Resonant frequency (MHz)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the slope with uncertainty from the fit parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-09T23:38:17.779134Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "# proton_slope = unc.ufloat(Line_fit.params['slope'].value, Line_fit.params['slope'].stderr,'proton_slope')\n",
    "# print('gamma for protons = {:.2uP} MHz/kG'.format(proton_slope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $\\gamma$ in rad/(s-T) to compare to accepted values.  Use the conversion constants in `scipy.constants` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-09T23:38:17.780121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here is an example of how to access the scipy.constants\n",
    "\n",
    "expected_gamma = const.value('nuclear magneton in MHz/T')*const.value('proton g factor')\n",
    "print('Expected value of gamma for proton: {:.6g} MHz/T'.format(expected_gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the proton $g$-factor from your result and compare to the expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-09T23:38:17.781295Z"
    }
   },
   "outputs": [],
   "source": [
    "# You code this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluorine-19 versus Proton (Hydrogen-1) resonance\n",
    "\n",
    "### Read in the data\n",
    "\n",
    "Also, print a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-09T23:38:17.782300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use pd.read_csv(), as you did earlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and fit the data.  \n",
    "\n",
    "BUT: Here you are comparing the resonant frequencies only!  The magnetic field measurement does not matter, as long as it is stable between the two frequency measurements for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-09T23:38:17.782887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a fit and plot of fluorine resonant frequency versus hydrogen resonant frequency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the result\n",
    "\n",
    "Obtain the slope with uncertainty and with the result calculate a value for $\\gamma_F$ and the <sup>19</sup>F $g$-factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-09T23:38:17.783394Z"
    }
   },
   "outputs": [],
   "source": [
    "# You code this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend of $T_2^*$ as a function of paramagnetic ion concentration\n",
    "\n",
    "From the scope screen images, extract estimates of the relaxation time $T_2^*$ as a function of concentration of the copper sulfate ions.  \n",
    "\n",
    "Plot these on a plot with double-log axes.  To change the axis type of a plot use the functions\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "You should see a trend that the relaxation time gets a bit longer and then levels out as the concentration is decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-09T23:38:17.783898Z"
    }
   },
   "outputs": [],
   "source": [
    "# You code this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:38:17.785360Z",
     "start_time": "2025-01-09T23:38:17.784368Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
